 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF'
diff --git a/app/main.py b/app/main.py
index 81307bcc5822c00745b3a66e66b25b4f2dd9a29f..71a4aab258dd5436cd548178d2dfdc06bc788a49 100644
--- a/app/main.py
+++ b/app/main.py
@@ -1,48 +1,52 @@
 """Application entry point for the Spectra desktop shell."""

 from __future__ import annotations

 import sys
 from pathlib import Path
-from typing import Dict, Iterable, List
+from typing import Dict, Iterable, List, Any

 import numpy as np

 from app.qt_compat import get_qt
-
-QtCore, QtGui, QtWidgets, QT_BINDING = get_qt()
-
 from .services import (
     UnitsService,
     ProvenanceService,
     DataIngestService,
     OverlayService,
     MathService,
+    Spectrum,
 )
 from .ui.plot_pane import PlotPane, TraceStyle

+QtCore: Any
+QtGui: Any
+QtWidgets: Any
+QT_BINDING: str
+QtCore, QtGui, QtWidgets, QT_BINDING = get_qt()
+
 SAMPLES_DIR = Path(__file__).resolve().parent.parent / "samples"


 class SpectraMainWindow(QtWidgets.QMainWindow):
     """Preview shell that wires UI actions to services with docked layout."""

     def __init__(self, container: object | None = None) -> None:
         super().__init__()
         self.setWindowTitle("Spectra Desktop Preview")
         self.resize(1320, 840)

         self.units_service = UnitsService()
         self.provenance_service = ProvenanceService()
         self.ingest_service = DataIngestService(self.units_service)
         self.overlay_service = OverlayService(self.units_service)
         self.math_service = MathService()

         self._dataset_items: Dict[str, QtGui.QStandardItem] = {}
         self._spectrum_colors: Dict[str, QtGui.QColor] = {}
         self._visibility: Dict[str, bool] = {}
         self._palette: List[QtGui.QColor] = [
             QtGui.QColor("#4F6D7A"),
             QtGui.QColor("#C0D6DF"),
             QtGui.QColor("#C72C41"),
             QtGui.QColor("#2F4858"),
@@ -320,70 +324,73 @@ class SpectraMainWindow(QtWidgets.QMainWindow):
         finally:
             self.plot.end_bulk_update()

     # Actions -----------------------------------------------------------
     def open_file(self) -> None:
         path, _ = QtWidgets.QFileDialog.getOpenFileName(
             self,
             "Open Spectrum",
             str(Path.home()),
             "Spectra (*.csv *.txt)",
         )
         if path:
             self._ingest_path(Path(path))

     def load_sample_via_menu(self) -> None:
         files = list(SAMPLES_DIR.glob('*.csv'))
         if not files:
             self.status_bar.showMessage("No samples found", 5000)
             return
         self._ingest_path(files[0])

     def export_manifest(self) -> None:
         if not self.overlay_service.list():
             QtWidgets.QMessageBox.information(self, "No Data", "Load spectra before exporting provenance.")
             return
-        manifest = self.provenance_service.create_manifest(self.overlay_service.list())
         save_path, _ = QtWidgets.QFileDialog.getSaveFileName(
             self,
             "Save Manifest",
             str(Path.home() / 'manifest.json'),
             "JSON (*.json)",
         )
         if save_path:
-            save_path = Path(save_path)
-            self.provenance_service.save_manifest(manifest, save_path)
-            self.status_bar.showMessage(f"Manifest saved to {save_path}", 5000)
-            self._log("Manifest", f"Saved to {save_path}")
-            image_path = save_path.with_suffix('.png')
+            manifest_path = Path(save_path)
             try:
-                self.plot.export_png(image_path)
+                export = self.provenance_service.export_bundle(
+                    self.overlay_service.list(),
+                    manifest_path,
+                    png_writer=self.plot.export_png,
+                )
             except Exception as exc:  # pragma: no cover - UI feedback
-                self._log("Export", f"Plot export failed: {exc}")
-            else:
-                self._log("Export", f"Plot snapshot saved to {image_path}")
-            self.provenance_view.setPlainText(json_pretty(manifest))
+                QtWidgets.QMessageBox.warning(self, "Export Failed", str(exc))
+                self._log("Export", f"Bundle export failed: {exc}")
+                return
+            self.status_bar.showMessage(f"Manifest saved to {export['manifest_path']}", 5000)
+            self._log("Manifest", f"Saved to {export['manifest_path']}")
+            self._log("Export", f"CSV saved to {export['csv_path']}")
+            self._log("Export", f"Plot snapshot saved to {export['png_path']}")
+            self.provenance_view.setPlainText(json_pretty(export['manifest']))
             self.provenance_view.show()
             self.prov_tree.show()
             self.prov_placeholder.hide()

     def refresh_overlay(self) -> None:
         selected_ids = self._selected_dataset_ids()
         if not selected_ids:
             selected_ids = [sid for sid, visible in self._visibility.items() if visible]
         if not selected_ids:
             self.data_table.clearContents()
             self.data_table.setRowCount(0)
             if self.data_table.isVisible():
                 self.data_table.hide()
                 self.data_table_action.setChecked(False)
             return
         selected_ids = [sid for sid in selected_ids if self._visibility.get(sid, True)]
         if not selected_ids:
             return
         views = self.overlay_service.overlay(
             selected_ids,
             self.unit_combo.currentText(),
             self._normalise_y("absorbance"),
         )
         self._populate_data_table(views)
         if not self.data_table.isVisible():
@@ -408,121 +415,121 @@ class SpectraMainWindow(QtWidgets.QMainWindow):
         if not ids:
             return
         spec_a = self.overlay_service.get(ids[0])
         spec_b = self.overlay_service.get(ids[1])
         result, info = self.math_service.ratio(spec_a, spec_b)
         self._log_math(info)
         self.overlay_service.add(result)
         self._add_spectrum(result)
         self._update_math_selectors()

     # Internal helpers --------------------------------------------------
     def _ingest_path(self, path: Path) -> None:
         try:
             spectrum = self.ingest_service.ingest(path)
         except Exception as exc:  # pragma: no cover - UI feedback
             QtWidgets.QMessageBox.critical(self, "Import failed", str(exc))
             return
         self.overlay_service.add(spectrum)
         self._add_spectrum(spectrum)
         self.status_bar.showMessage(f"Loaded {path.name}", 5000)
         self._update_math_selectors()
         self.refresh_overlay()
         self._show_metadata(spectrum)
         self._show_provenance(spectrum)

-    def _add_spectrum(self, spectrum: 'Spectrum') -> None:
+    def _add_spectrum(self, spectrum: Spectrum) -> None:
         color = self._assign_color(spectrum)
         group_item = self._derived_item if self._is_derived(spectrum) else self._originals_item
         visible_item = QtGui.QStandardItem()
         visible_item.setCheckable(True)
         visible_item.setCheckState(QtCore.Qt.CheckState.Checked)
         visible_item.setEditable(False)
         visible_item.setData(spectrum.id, QtCore.Qt.ItemDataRole.UserRole)

         color_item = QtGui.QStandardItem()
         color_item.setEditable(False)
         icon_pix = QtGui.QPixmap(16, 16)
         icon_pix.fill(color)
         color_item.setIcon(QtGui.QIcon(icon_pix))
         color_item.setData(spectrum.id, QtCore.Qt.ItemDataRole.UserRole)

         alias_item = QtGui.QStandardItem(spectrum.name)
         alias_item.setEditable(False)
         alias_item.setData(spectrum.id, QtCore.Qt.ItemDataRole.UserRole)
         group_item.appendRow([alias_item, visible_item, color_item])
         self.dataset_tree.expandAll()
         self._dataset_items[spectrum.id] = alias_item
         self._visibility[spectrum.id] = True
         self._add_plot_trace(spectrum, color)

-    def _add_plot_trace(self, spectrum: 'Spectrum', color: QtGui.QColor) -> None:
+    def _add_plot_trace(self, spectrum: Spectrum, color: QtGui.QColor) -> None:
         alias_item = self._dataset_items.get(spectrum.id)
         alias = alias_item.text() if alias_item else spectrum.name
         x_nm = self._to_nm(spectrum.x, spectrum.x_unit)
         style = TraceStyle(
             color=QtGui.QColor(color),
             width=1.6,
             antialias=False,
             show_in_legend=True,
         )
         self.plot.add_trace(
             key=spectrum.id,
             alias=alias,
             x_nm=x_nm,
             y=spectrum.y,
             style=style,
         )
         self.plot.autoscale()

-    def _show_metadata(self, spectrum: 'Spectrum | None') -> None:
+    def _show_metadata(self, spectrum: Spectrum | None) -> None:
         if spectrum is None:
             self.info_panel.hide()
             self.info_placeholder.show()
             return

         alias_item = self._dataset_items.get(spectrum.id)
         alias_text = alias_item.text() if alias_item else spectrum.name
         self.info_name.setText(spectrum.name)
         self.info_alias.setText(alias_text)
         source = spectrum.source_path.name if spectrum.source_path else "N/A"
         self.info_source.setText(source)
         self.info_units.setText(f"x: {spectrum.x_unit} | y: {spectrum.y_unit}")
         if spectrum.x.size:
             self.info_range_x.setText(f"{float(spectrum.x.min()):.4g} – {float(spectrum.x.max()):.4g} {spectrum.x_unit}")
             self.info_points.setText(str(int(spectrum.x.size)))
         else:
             self.info_range_x.setText("–")
             self.info_points.setText("0")
         if spectrum.y.size:
             self.info_range_y.setText(f"{float(spectrum.y.min()):.4g} – {float(spectrum.y.max()):.4g} {spectrum.y_unit}")
         else:
             self.info_range_y.setText("–")
         self.info_panel.show()
         self.info_placeholder.hide()

-    def _show_provenance(self, spectrum: 'Spectrum | None') -> None:
+    def _show_provenance(self, spectrum: Spectrum | None) -> None:
         if spectrum is None:
             self.prov_tree.clear()
             self.provenance_view.clear()
             self.prov_tree.hide()
             self.provenance_view.hide()
             self.prov_placeholder.show()
             return

         self.prov_tree.clear()
         root = QtWidgets.QTreeWidgetItem([spectrum.name, spectrum.id])
         self.prov_tree.addTopLevelItem(root)

         parents = getattr(spectrum, 'parents', ())
         if parents:
             parents_node = QtWidgets.QTreeWidgetItem(["Parents", ", ".join(parents)])
             root.addChild(parents_node)

         transforms = getattr(spectrum, 'transforms', ())
         for transform in transforms:
             node = QtWidgets.QTreeWidgetItem([
                 transform.get('name', transform.get('operation', 'Transform')),
                 json_pretty(transform),
             ])
             root.addChild(node)

@@ -564,73 +571,73 @@ class SpectraMainWindow(QtWidgets.QMainWindow):
     def _update_math_selectors(self) -> None:
         spectra = self.overlay_service.list()
         self.math_a.clear()
         self.math_b.clear()
         for spec in spectra:
             alias_item = self._dataset_items.get(spec.id)
             display_name = alias_item.text() if alias_item else spec.name
             self.math_a.addItem(display_name, spec.id)
             self.math_b.addItem(display_name, spec.id)

     def _selected_math_ids(self) -> list[str]:
         if self.math_a.count() < 2 or self.math_b.count() < 2:
             QtWidgets.QMessageBox.information(self, "Need more spectra", "Load at least two spectra for math operations.")
             return []
         return [self.math_a.currentData(), self.math_b.currentData()]

     def _log_math(self, info: dict) -> None:
         new_line = json_pretty(info)
         self.math_log.appendPlainText(new_line)
         self._log("Math", new_line)

     def _normalise_y(self, label: str) -> str:
         mapping = {"%T": "percent_transmittance"}
         return mapping.get(label, label)

-    def _assign_color(self, spectrum: 'Spectrum') -> QtGui.QColor:
+    def _assign_color(self, spectrum: Spectrum) -> QtGui.QColor:
         if spectrum.id in self._spectrum_colors:
             return self._spectrum_colors[spectrum.id]

         color: QtGui.QColor | None = None
         metadata = spectrum.metadata if isinstance(spectrum.metadata, dict) else {}
         operation = metadata.get('operation') if isinstance(metadata, dict) else None
         parents: List[str] = []
         if isinstance(operation, dict):
             parents = list(operation.get('parents') or [])
         if parents:
             base_id = parents[0]
             base_color = self._spectrum_colors.get(base_id)
             if base_color:
                 color = QtGui.QColor(base_color)
                 color = color.lighter(130)
         if color is None:
             color = self._palette[self._palette_index % len(self._palette)]
             self._palette_index += 1
         self._spectrum_colors[spectrum.id] = color
         return color

-    def _is_derived(self, spectrum: 'Spectrum') -> bool:
+    def _is_derived(self, spectrum: Spectrum) -> bool:
         metadata = spectrum.metadata
         if isinstance(metadata, dict) and 'operation' in metadata:
             return True
         return bool(getattr(spectrum, 'parents', ()))

     def _to_nm(self, x: np.ndarray, unit: str) -> np.ndarray:
         data = np.asarray(x, dtype=np.float64)
         if unit == "nm":
             return data
         if unit in ("Angstrom", "Å"):
             return data / 10.0
         if unit in ("um", "µm"):
             return data * 1000.0
         if unit in ("cm^-1", "cm⁻¹"):
             with np.errstate(divide='ignore'):
                 return 1e7 / data
         return data

     def _selected_dataset_ids(self) -> list[str]:
         selection = self.dataset_tree.selectionModel()
         if not selection:
             return []
         ids: list[str] = []
         for index in selection.selectedRows():
             item = self.dataset_model.itemFromIndex(index)
diff --git a/app/services/__init__.py b/app/services/__init__.py
index b0e8b334301205bc4b0b2c2b70cef0470fb45cf9..646f4e685ba66204f960576a6662f3e9f0130f71 100644
--- a/app/services/__init__.py
+++ b/app/services/__init__.py
@@ -1,18 +1,20 @@
 """Service layer for the Spectra application."""

 from .spectrum import Spectrum
 from .units_service import UnitError, UnitsService
 from .provenance_service import ProvenanceService
 from .data_ingest_service import DataIngestService
 from .overlay_service import OverlayService
 from .math_service import MathService
+from .store import LocalStore

 __all__ = [
     "Spectrum",
     "UnitError",
     "UnitsService",
     "ProvenanceService",
     "DataIngestService",
     "OverlayService",
     "MathService",
+    "LocalStore",
 ]
diff --git a/app/services/data_ingest.py b/app/services/data_ingest.py
deleted file mode 100644
index 691b835eaf2ec26c294e67776c6735dbf95dbe05..0000000000000000000000000000000000000000
--- a/app/services/data_ingest.py
+++ /dev/null
@@ -1,97 +0,0 @@
-"""Service responsible for ingesting spectra via registered importers."""
-
-from __future__ import annotations
-
-from dataclasses import dataclass, field
-from pathlib import Path
-from typing import Dict, List, Optional
-import hashlib
-import logging
-
-from .spectrum import Spectrum
-from .units_service import UnitsService
-from .provenance_service import ProvenanceService
-from . import importers
-
-logger = logging.getLogger(__name__)
-
-
-@dataclass
-class DataIngestService:
-    """Load spectra from disk while preserving provenance."""
-
-    units_service: UnitsService
-    provenance_service: ProvenanceService
-    _importers: Dict[str, importers.Importer] = field(default_factory=dict)
-
-    def __post_init__(self) -> None:
-        if not self._importers:
-            self.register_importer(importers.CsvImporter())
-
-    def register_importer(self, importer: importers.Importer) -> None:
-        for ext in importer.supported_extensions:
-            self._importers[ext.lower()] = importer
-
-    def available_formats(self) -> List[str]:
-        return sorted(set(self._importers.keys()))
-
-    def ingest(self, path: Path, *, display_name: Optional[str] = None) -> Spectrum:
-        importer = self._select_importer(path)
-        result = importer.read(path)
-        logger.info("Ingesting %s via %s", path, importer.description())
-
-        wavelength_nm = self.units_service.convert_wavelength(
-            result.wavelengths, result.wavelength_unit, self.units_service.canonical_wavelength_unit
-        )
-        flux_context = dict(result.metadata.get("flux_context", {}))
-        flux = self.units_service.convert_flux(
-            result.flux,
-            result.flux_unit,
-            self.units_service.canonical_flux_unit,
-            context=flux_context,
-        )
-
-        checksum = self._sha256(path)
-        metadata = {
-            "source": {
-                "path": str(path),
-                "checksum": checksum,
-                "importer": importer.__class__.__name__,
-                "wavelength_unit": result.wavelength_unit,
-                "flux_unit": result.flux_unit,
-            },
-            "comments": result.metadata.get("comments", []),
-            "x_label": result.metadata.get("x_label"),
-            "y_label": result.metadata.get("y_label"),
-            "flux_context": flux_context,
-        }
-
-        provenance_entry = {
-            "event": "ingest",
-            "importer": importer.__class__.__name__,
-            "timestamp": self.provenance_service.timestamp(),
-            "checksum": checksum,
-        }
-
-        return Spectrum.create(
-            name=display_name or path.stem,
-            wavelength_nm=wavelength_nm,
-            flux=flux,
-            flux_unit=self.units_service.canonical_flux_unit,
-            metadata=metadata,
-            provenance=[provenance_entry],
-        )
-
-    def _select_importer(self, path: Path) -> importers.Importer:
-        ext = path.suffix.lower()
-        if ext in self._importers:
-            return self._importers[ext]
-        raise ValueError(f"No importer registered for extension '{ext}'")
-
-    @staticmethod
-    def _sha256(path: Path) -> str:
-        digest = hashlib.sha256()
-        with path.open("rb") as handle:
-            for chunk in iter(lambda: handle.read(8192), b""):
-                digest.update(chunk)
-        return digest.hexdigest()
diff --git a/app/services/data_ingest_service.py b/app/services/data_ingest_service.py
index b634c3cd4262a4bf55e327edfc9122ec61d08748..602c5faa3a903a5bd5e4c78dd0b05a1c9b509293 100644
--- a/app/services/data_ingest_service.py
+++ b/app/services/data_ingest_service.py
@@ -1,48 +1,49 @@
 """Data ingestion pipeline for the Spectra application."""

 from __future__ import annotations

 from dataclasses import dataclass, field
 from pathlib import Path
-from typing import Dict, Callable, Iterable
+from typing import Dict, Iterable

 from .spectrum import Spectrum
 from .units_service import UnitsService
-from .importers import SupportsImport, CsvImporter
+from .importers import SupportsImport, CsvImporter, FitsImporter


 @dataclass
 class DataIngestService:
     """Manage importer plugins and normalise spectra into canonical units."""

     units_service: UnitsService
     _registry: Dict[str, SupportsImport] = field(default_factory=dict)

     def __post_init__(self) -> None:
         if not self._registry:
             self.register_importer({'.csv', '.txt'}, CsvImporter())
+            self.register_importer({'.fits', '.fit', '.fts'}, FitsImporter())

     # ------------------------------------------------------------------
     def register_importer(self, extensions: Iterable[str], importer: SupportsImport) -> None:
         """Register an importer for the provided file extensions."""
         for ext in extensions:
             key = ext.lower()
             if not key.startswith('.'):  # normalise to .ext format
                 key = f'.{key}'
             self._registry[key] = importer

     def ingest(self, path: Path) -> Spectrum:
         """Read a file from disk and return a canonical :class:`Spectrum`."""
         ext = path.suffix.lower()
         importer = self._registry.get(ext)
         if importer is None:
             raise ValueError(f"No importer registered for extension {ext!r}")

         raw = importer.read(path)
         canonical_x, canonical_y, metadata = self.units_service.to_canonical(
             raw.x, raw.y, raw.x_unit, raw.y_unit, metadata=raw.metadata
         )
         metadata.setdefault('ingest', {})
         metadata['ingest'].update({
             'source_path': str(raw.source_path or path),
             'importer': importer.__class__.__name__,
diff --git a/app/services/importers/__init__.py b/app/services/importers/__init__.py
index 619faf7def026e4b602b67b0cf6a077ea4802713..955d1c552ad49af8d4df2a08bc27d5a07e82ccbc 100644
--- a/app/services/importers/__init__.py
+++ b/app/services/importers/__init__.py
@@ -1,6 +1,7 @@
 """Importer classes for different file formats."""

 from .base import ImporterResult, SupportsImport
 from .csv_importer import CsvImporter
+from .fits_importer import FitsImporter

-__all__ = ["ImporterResult", "SupportsImport", "CsvImporter"]
+__all__ = ["ImporterResult", "SupportsImport", "CsvImporter", "FitsImporter"]
diff --git a/app/services/importers/fits_importer.py b/app/services/importers/fits_importer.py
new file mode 100644
index 0000000000000000000000000000000000000000..36361e91fe2b9dd4f2961726151057df6bd2e037
--- /dev/null
+++ b/app/services/importers/fits_importer.py
@@ -0,0 +1,101 @@
+"""FITS importer for one-dimensional spectra."""
+
+from __future__ import annotations
+
+from pathlib import Path
+from typing import Iterable
+
+import numpy as np
+from astropy.io import fits
+
+from .base import ImporterResult
+
+
+class FitsImporter:
+    """Load spectral columns from FITS binary tables."""
+
+    _WAVELENGTH_COLUMNS: Iterable[str] = (
+        "wavelength",
+        "wave",
+        "lambda",
+        "lam",
+        "x",
+    )
+    _FLUX_COLUMNS: Iterable[str] = (
+        "flux",
+        "intensity",
+        "counts",
+        "signal",
+        "y",
+    )
+
+    def read(self, path: Path) -> ImporterResult:
+        path = Path(path)
+        with fits.open(path, memmap=False) as hdul:
+            hdu = self._select_hdu(hdul)
+            data = hdu.data
+            if data is None:
+                raise ValueError(f"No tabular data found in {path}")
+
+            wave_col = self._find_column(hdu, self._WAVELENGTH_COLUMNS)
+            flux_col = self._find_column(hdu, self._FLUX_COLUMNS)
+
+            x = np.asarray(data[wave_col], dtype=np.float64)
+            y = np.asarray(data[flux_col], dtype=np.float64)
+
+            x_unit = self._column_unit(hdu, wave_col) or "nm"
+            flux_unit = self._column_unit(hdu, flux_col) or hdu.header.get("BUNIT", "")
+
+            name = hdu.header.get("OBJECT", path.stem)
+            metadata = {
+                "x_label": wave_col,
+                "y_label": flux_col,
+                "fits_header": {key: hdu.header.get(key) for key in ("OBJECT", "INSTRUME", "TELESCOP") if key in hdu.header},
+            }
+            if flux_unit:
+                metadata["original_flux_unit"] = str(flux_unit).lower()
+
+        y_unit = self._normalise_intensity_unit(flux_unit)
+        return ImporterResult(
+            name=name,
+            x=x,
+            y=y,
+            x_unit=str(x_unit).lower(),
+            y_unit=y_unit,
+            metadata=metadata,
+            source_path=path,
+        )
+
+    def description(self) -> str:
+        return "FITS binary table importer"
+
+    def _select_hdu(self, hdulist: fits.HDUList) -> fits.BinTableHDU:
+        for hdu in hdulist:
+            if isinstance(hdu, fits.BinTableHDU) and hdu.data is not None:
+                return hdu
+        raise ValueError("No binary table HDU found for spectral data")
+
+    def _find_column(self, hdu: fits.BinTableHDU, candidates: Iterable[str]) -> str:
+        names = {name.lower(): name for name in hdu.columns.names or []}
+        for candidate in candidates:
+            if candidate.lower() in names:
+                return names[candidate.lower()]
+        raise ValueError(f"Required column not found; expected one of {candidates}")
+
+    def _column_unit(self, hdu: fits.BinTableHDU, column: str) -> str | None:
+        try:
+            unit = hdu.columns[column].unit
+        except (KeyError, AttributeError):
+            unit = None
+        if unit:
+            return str(unit)
+        return None
+
+    def _normalise_intensity_unit(self, unit: str | None) -> str:
+        if not unit:
+            return "absorbance"
+        normalised = unit.strip().lower()
+        supported = {"absorbance", "a10", "transmittance", "t", "percent_transmittance", "%t", "absorbance_e", "ae"}
+        if normalised in supported:
+            return normalised
+        return "absorbance"
diff --git a/app/services/provenance_service.py b/app/services/provenance_service.py
index 694a5f18e29dec4ad113da6174708877b4c2a6d1..276123499c735f0720f5477d5e34540f3c6fa68d 100644
--- a/app/services/provenance_service.py
+++ b/app/services/provenance_service.py
@@ -1,73 +1,119 @@
-"""Generate and parse provenance manifests."""
+"""Generate and persist provenance manifests and export bundles."""

 from __future__ import annotations

-from dataclasses import dataclass, field
+from dataclasses import dataclass
 from datetime import datetime, timezone
 from importlib import metadata
 from pathlib import Path
-from typing import Iterable, Dict, Any, List, Optional
+import csv
+from typing import Iterable, Dict, Any, List, Optional, Callable
 import hashlib
 import json

 from .spectrum import Spectrum


 @dataclass
 class ProvenanceService:
     """Service for creating and persisting provenance manifests."""

     app_name: str = "SpectraApp"
     app_version: str = "0.1.0"

     def create_manifest(
         self,
         spectra: Iterable[Spectrum],
         transforms: Optional[List[Dict[str, Any]]] = None,
         citations: Optional[List[Dict[str, Any]]] = None,
     ) -> Dict[str, Any]:
         """Create a provenance manifest for the provided spectra."""

         spectra_list = list(spectra)
         source_entries = [self._source_entry(spec) for spec in spectra_list]
         manifest = {
             "version": "1.0",
             "app": self._app_metadata(),
             "timestamp_utc": datetime.now(timezone.utc).isoformat(),
             "sources": source_entries,
             "transforms": [self._normalise_transform(t) for t in (transforms or [])],
             "citations": citations or [],
         }
         return manifest

     def save_manifest(self, manifest: Dict[str, Any], path: Path) -> None:
         path.parent.mkdir(parents=True, exist_ok=True)
         with path.open('w', encoding='utf-8') as f:
             json.dump(manifest, f, indent=2, ensure_ascii=False)

+    def export_bundle(
+        self,
+        spectra: Iterable[Spectrum],
+        manifest_path: Path,
+        *,
+        transforms: Optional[List[Dict[str, Any]]] = None,
+        citations: Optional[List[Dict[str, Any]]] = None,
+        csv_path: Path | None = None,
+        png_path: Path | None = None,
+        png_writer: Callable[[Path], None] | None = None,
+    ) -> Dict[str, Any]:
+        """Create a provenance bundle containing manifest, data, and plot artefacts."""
+
+        spectra_list = list(spectra)
+        manifest = self.create_manifest(spectra_list, transforms=transforms, citations=citations)
+
+        manifest_path = Path(manifest_path)
+        self.save_manifest(manifest, manifest_path)
+
+        csv_file = Path(csv_path) if csv_path is not None else manifest_path.with_suffix('.csv')
+        self._write_csv(csv_file, spectra_list)
+
+        png_file = Path(png_path) if png_path is not None else manifest_path.with_suffix('.png')
+        png_file.parent.mkdir(parents=True, exist_ok=True)
+        if png_writer is not None:
+            png_writer(png_file)
+        else:
+            png_file.touch(exist_ok=True)
+
+        return {
+            "manifest": manifest,
+            "manifest_path": manifest_path,
+            "csv_path": csv_file,
+            "png_path": png_file,
+        }
+
     # ------------------------------------------------------------------
+    def _write_csv(self, path: Path, spectra: Iterable[Spectrum]) -> None:
+        path.parent.mkdir(parents=True, exist_ok=True)
+        with path.open('w', newline='', encoding='utf-8') as handle:
+            writer = csv.writer(handle)
+            writer.writerow(['spectrum_id', 'name', 'wavelength_nm', 'intensity', 'x_unit', 'y_unit'])
+            for spectrum in spectra:
+                for x_val, y_val in zip(spectrum.x, spectrum.y):
+                    writer.writerow([spectrum.id, spectrum.name, float(x_val), float(y_val), spectrum.x_unit, spectrum.y_unit])
+
     def _source_entry(self, spectrum: Spectrum) -> Dict[str, Any]:
         entry: Dict[str, Any] = {
             "id": spectrum.id,
             "name": spectrum.name,
             "units": {
                 "wavelength": spectrum.x_unit,
                 "intensity": spectrum.y_unit,
             },
             "metadata": spectrum.metadata,
             "parents": list(getattr(spectrum, 'parents', [])),
             "transforms": list(getattr(spectrum, 'transforms', [])),
         }
         if spectrum.source_path and spectrum.source_path.exists():
             entry.update({
                 "path": str(spectrum.source_path),
                 "size_bytes": spectrum.source_path.stat().st_size,
                 "checksum_sha256": self._sha256(spectrum.source_path),
             })
         return entry

     def _app_metadata(self) -> Dict[str, Any]:
         libraries = {}
         for package in ("numpy", "pyside6", "pytest"):
             try:
                 libraries[package] = metadata.version(package)
diff --git a/app/services/store.py b/app/services/store.py
new file mode 100644
index 0000000000000000000000000000000000000000..8aa0b1a4b3be932995bc93d28bc815cc76b3d8ab
--- /dev/null
+++ b/app/services/store.py
@@ -0,0 +1,138 @@
+
+"""Local persistence for ingested spectra and provenance manifests."""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from datetime import datetime, timezone
+import hashlib
+import json
+import os
+from pathlib import Path
+import shutil
+import sys
+from typing import Any, Callable, Dict, Mapping, MutableMapping
+
+
+_INDEX_TEMPLATE: Dict[str, Any] = {"version": 1, "items": {}}
+
+
+@dataclass
+class LocalStore:
+    """Persist ingested spectra into the application data directory."""
+
+    app_name: str = "SpectraApp"
+    base_dir: Path | None = None
+    env: Mapping[str, str] | None = None
+    clock: Callable[..., datetime] = datetime.now
+    _index_cache: Dict[str, Any] = field(default_factory=dict, init=False)
+
+    @property
+    def data_dir(self) -> Path:
+        if self.base_dir is not None:
+            return Path(self.base_dir)
+        environ: Mapping[str, str] = self.env or os.environ
+        appdata = environ.get("APPDATA")
+        if appdata:
+            return Path(appdata) / self.app_name / "data"
+        if sys.platform == "darwin":
+            return Path.home() / "Library" / "Application Support" / self.app_name / "data"
+        if sys.platform == "win32":
+            return Path.home() / "AppData" / "Roaming" / self.app_name / "data"
+        return Path.home() / ".local" / "share" / self.app_name / "data"
+
+    @property
+    def index_path(self) -> Path:
+        return self.data_dir / "index.json"
+
+    def load_index(self) -> Dict[str, Any]:
+        if self._index_cache:
+            return self._index_cache
+        path = self.index_path
+        if not path.exists():
+            self._index_cache = json.loads(json.dumps(_INDEX_TEMPLATE))
+            return self._index_cache
+        with path.open("r", encoding="utf-8") as handle:
+            self._index_cache = json.load(handle)
+        self._index_cache.setdefault("version", 1)
+        self._index_cache.setdefault("items", {})
+        return self._index_cache
+
+    def save_index(self, index: MutableMapping[str, Any] | None = None) -> None:
+        self.data_dir.mkdir(parents=True, exist_ok=True)
+        payload = index or self.load_index()
+        with self.index_path.open("w", encoding="utf-8") as handle:
+            json.dump(payload, handle, indent=2, ensure_ascii=False)
+        self._index_cache = json.loads(json.dumps(payload))
+
+    def record(
+        self,
+        source_path: Path,
+        *,
+        x_unit: str,
+        y_unit: str,
+        source: Mapping[str, Any] | None = None,
+        manifest_path: Path | None = None,
+        alias: str | None = None,
+    ) -> Dict[str, Any]:
+        source_path = Path(source_path)
+        stored_path = self._copy_into_store(source_path, alias=alias)
+        checksum = self._sha256(stored_path)
+
+        index = self.load_index()
+        items: MutableMapping[str, Any] = index.setdefault("items", {})  # type: ignore[assignment]
+        entry = dict(items.get(checksum, {}))
+        created = entry.get("created", self._timestamp())
+
+        entry.update(
+            {
+                "sha256": checksum,
+                "filename": stored_path.name,
+                "stored_path": str(stored_path),
+                "original_path": str(source_path),
+                "bytes": stored_path.stat().st_size,
+                "units": {"x": x_unit, "y": y_unit},
+                "source": dict(source or {}),
+                "created": created,
+                "updated": self._timestamp(),
+            }
+        )
+        if manifest_path is not None:
+            entry["manifest_path"] = str(manifest_path)
+        items[checksum] = entry
+        self.save_index(index)
+        return entry
+
+    def list_entries(self) -> Dict[str, Any]:
+        return self.load_index().get("items", {})
+
+    # ------------------------------------------------------------------
+    def _copy_into_store(self, source_path: Path, alias: str | None = None) -> Path:
+        checksum = self._sha256(source_path)
+        target_dir = self.data_dir / "files" / checksum[:2]
+        target_dir.mkdir(parents=True, exist_ok=True)
+        filename = alias or source_path.name
+        target_path = target_dir / filename
+        if not target_path.exists():
+            shutil.copy2(source_path, target_path)
+        return target_path
+
+    @staticmethod
+    def _sha256(path: Path) -> str:
+        digest = hashlib.sha256()
+        with path.open("rb") as handle:
+            for chunk in iter(lambda: handle.read(8192), b""):
+                digest.update(chunk)
+        return digest.hexdigest()
+
+    def _timestamp(self) -> str:
+        clock = self.clock
+        try:
+            moment = clock(timezone.utc)  # type: ignore[misc]
+        except TypeError:  # clock without tz argument
+            moment = clock()  # type: ignore[misc]
+        if not isinstance(moment, datetime):
+            moment = datetime.now(timezone.utc)
+        if moment.tzinfo is None:
+            moment = moment.replace(tzinfo=timezone.utc)
+        return moment.isoformat()
diff --git a/app/services/units_service.py b/app/services/units_service.py
index 48e50984670ea08e927861db905481231363c948..8fa5341ca0956bd08b0a4d41f41efb698d608a82 100644
--- a/app/services/units_service.py
+++ b/app/services/units_service.py
@@ -1,80 +1,85 @@
 """Unit conversion utilities for spectra.

 This module centralises conversions for wavelength and intensity units as
 specified in ``specs/units_and_conversions.md``.  The application stores
 spectral data internally using the canonical baseline of nanometres for the
 independent axis and base-10 absorbance for the dependent axis.  All derived
 views are generated from the canonical arrays so that round-trips are free of
 numerical drift and the original data is never mutated.
 """

+
 from __future__ import annotations

 from dataclasses import dataclass, field
-from typing import Dict, Any, Tuple
+from typing import Dict, Any, Tuple, TYPE_CHECKING

 import numpy as np

+if TYPE_CHECKING:
+    from .spectrum import Spectrum
+else:
+    Spectrum = Any
+

 _CANONICAL_X_UNIT = "nm"
 _CANONICAL_Y_UNIT = "absorbance"  # Base-10 absorbance (A10)


 class UnitError(ValueError):
     """Raised when an unsupported unit is encountered."""


 @dataclass
 class UnitsService:
     """Perform conversions between spectral units.

     The service exposes helpers to convert arbitrary wavelength and intensity
     units into the canonical representation as well as utilities to derive new
     views from a canonical :class:`~app.services.spectrum.Spectrum` instance.
     No method mutates the input arrays; new :class:`numpy.ndarray` instances are
     returned for every conversion.
     """

-    float_dtype: np.dtype = field(default=np.float64)
+    float_dtype: np.dtype = field(default_factory=lambda: np.dtype(np.float64))

     # --- Public API -----------------------------------------------------
-    def convert(self, spectrum: "Spectrum", x_unit: str, y_unit: str) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
+    def convert(self, spectrum: Spectrum, x_unit: str, y_unit: str) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
         """Convert a canonical spectrum to the requested display units.

         Args:
             spectrum: Spectrum stored in canonical units (nm / absorbance).
             x_unit: Desired display unit for the X axis.
             y_unit: Desired display unit for the Y axis.

         Returns:
             Tuple of ``(x_array, y_array, metadata)`` where the arrays are new
             NumPy arrays in ``float_dtype`` and ``metadata`` captures the
             conversions performed.
         """

-        from .spectrum import Spectrum  # local import to avoid circular ref

         if spectrum.x_unit != _CANONICAL_X_UNIT:
             raise UnitError(
                 "Spectrum.x_unit must be canonical 'nm' before conversion; received "
                 f"{spectrum.x_unit!r}"
             )
         if spectrum.y_unit != _CANONICAL_Y_UNIT:
             raise UnitError(
                 "Spectrum.y_unit must be canonical 'absorbance' before conversion; received "
                 f"{spectrum.y_unit!r}"
             )

         x = self._from_canonical_wavelength(spectrum.x, x_unit)
         y = self._from_canonical_intensity(spectrum.y, y_unit)
         metadata: Dict[str, Any] = {}
         if x_unit != _CANONICAL_X_UNIT:
             metadata["x_conversion"] = f"{_CANONICAL_X_UNIT}→{x_unit}"
         if y_unit != _CANONICAL_Y_UNIT:
             metadata["y_conversion"] = f"{_CANONICAL_Y_UNIT}→{y_unit}"
         return x, y, metadata

     def to_canonical(self, x: np.ndarray, y: np.ndarray, x_unit: str, y_unit: str,
                      metadata: Dict[str, Any] | None = None) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
         """Convert arbitrary units into the canonical baseline.

diff --git a/app/ui/plot_pane.py b/app/ui/plot_pane.py
index 11c8b35244ce8e36ba7b9011420f16e21914be58..0c4e1946740f54b2b7bf29bac370d87606eb428e 100644
--- a/app/ui/plot_pane.py
+++ b/app/ui/plot_pane.py
@@ -1,39 +1,43 @@
 """Reusable plotting pane for spectral traces."""

 from __future__ import annotations

 from dataclasses import dataclass
 from pathlib import Path
-from typing import Dict
+from typing import Dict, Any

 import numpy as np
 import pyqtgraph as pg
 import pyqtgraph.exporters

 from app.qt_compat import get_qt

+QtCore: Any
+QtGui: Any
+QtWidgets: Any
+_: Any
 QtCore, QtGui, QtWidgets, _ = get_qt()


 @dataclass
 class TraceStyle:
     """Styling parameters for plot traces."""

     color: QtGui.QColor
     width: float = 1.5
     # Accepted for backwards compatibility but ignored by pyqtgraph 0.13.x.
     antialias: bool = False
     show_in_legend: bool = True


 class PlotPane(QtWidgets.QWidget):
     """Central plotting widget with legend, crosshair, and multi-trace support."""

     unitChanged = QtCore.Signal(str)
     pointHovered = QtCore.Signal(float, float)

     def __init__(self, parent: QtWidgets.QWidget | None = None) -> None:
         super().__init__(parent)
         self._display_unit = "nm"
         self._traces: Dict[str, Dict[str, object]] = {}
         self._order: list[str] = []
diff --git a/docs/dev/ingest_pipeline.md b/docs/dev/ingest_pipeline.md
new file mode 100644
index 0000000000000000000000000000000000000000..86ed438d112567257d34ac7bb424c54842ff6ba6
--- /dev/null
+++ b/docs/dev/ingest_pipeline.md
@@ -0,0 +1,28 @@
+# Ingest Pipeline Overview
+
+```
+      ┌──────────────┐      ┌───────────────┐      ┌──────────────────┐
+      │ File chooser │ ---> │ Importer plug │ ---> │ UnitsService      │
+      └──────────────┘      │  (CSV/FITS/   │      │ to canonical nm  │
+                            │   JCAMP)      │      │ + absorbance     │
+                            └───────────────┘      └──────────────────┘
+                                     │                         │
+                                     ▼                         ▼
+                               ┌────────────┐         ┌──────────────────┐
+                               │ Spectrum   │ <------ │ Provenance entry │
+                               │ (canonical │         │ + LocalStore     │
+                               │   nm/A10)  │         └──────────────────┘
+```
+
+- Every importer reports the source units. The `UnitsService` normalises the
+  wavelength array into **nanometres**; intensities are converted into base-10
+  absorbance when possible. Raw units are kept in the metadata under
+  `source_units` and `original_flux_unit`.
+- The resulting `Spectrum` is immutable. Derived views use unit conversions at
+  display time, so toggling units is idempotent and never mutates the stored
+  arrays.
+- The `LocalStore` copies the raw file to `%APPDATA%/SpectraApp/data` (or the
+  platform equivalent) and records a `sha256` checksum alongside unit metadata.
+  This makes repeat loads instantaneous and ensures provenance is reproducible.
+- Provenance exports call `ProvenanceService.export_bundle`, which writes a
+  manifest, a canonical CSV snapshot, and a PNG plot into the selected folder.
diff --git a/docs/reviews/workplan.md b/docs/reviews/workplan.md
new file mode 100644
index 0000000000000000000000000000000000000000..c169ea95dec5d2bb27a2cef8e4a2bfe669473d78
--- /dev/null
+++ b/docs/reviews/workplan.md
@@ -0,0 +1,16 @@
+# Workplan — Batch 1 (2025-10-14)
+
+- [x] Seed tiny fixtures for tests (`tests/data/mini.*`).
+- [x] Lock in unit round-trip behavior (`tests/test_units_roundtrip.py`).
+- [x] Implement local store service and cache index tests.
+- [x] Ensure provenance export emits manifest bundle.
+- [x] Guard plot performance with LOD cap test.
+- [x] Update user and developer documentation (importing + ingest pipeline).
+- [x] Run lint/type/test suite locally; confirm CI configuration.
+- [ ] Smoke-check app launch, CSV/FITS ingest, unit toggle, export manifest.
+
+## Batch 1 QA Log
+
+- 2025-10-14: ✅ `ruff check app tests`
+- 2025-10-14: ✅ `mypy app --ignore-missing-imports`
+- 2025-10-14: ✅ `pytest -q --maxfail=1 --disable-warnings`
diff --git a/docs/user/importing.md b/docs/user/importing.md
new file mode 100644
index 0000000000000000000000000000000000000000..d36f9f2974ce7219cdb63b4a677d1d5e20039af9
--- /dev/null
+++ b/docs/user/importing.md
@@ -0,0 +1,27 @@
+# Importing Local Spectra
+
+The Import dialog accepts comma-separated text, JCAMP-DX, and FITS spectra. All
+files are normalised into the app's canonical wavelength baseline of
+nanometres while preserving the raw arrays on disk for provenance.
+
+## Supported formats
+
+- **CSV/TXT** – First column is wavelength, second is intensity. Units can be
+  specified in parentheses (e.g. `wavelength(nm)` or `transmittance`).
+- **FITS** – 1D binary tables with wavelength and flux columns. The importer
+  looks for standard names such as `WAVELENGTH`, `WAVE`, or `FLUX`. Original
+  header metadata is preserved in the provenance panel.
+- **JCAMP-DX** – Compact infrared/UV spectral files using `##XYDATA` blocks.
+
+## How to import
+
+1. Choose **File → Open** and select one or more spectra.
+2. Review the detected units shown in the preview banner.
+3. Confirm the ingest. The data is copied into the local cache (see
+   `docs/dev/ingest_pipeline.md`) so that reloading the same file is
+   instantaneous.
+
+Imported spectra always appear in canonical units inside the application. Use
+ the unit toggle on the toolbar to view alternative axes without mutating the
+ underlying data. The raw source file remains untouched in the provenance
+ bundle created during export.
diff --git a/requirements.txt b/requirements.txt
index dd165592133c1bc8683d626b5769a146f0b57119..1532b4f3fdb4901a82be51d07b295c0c0ade562b 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,4 +1,6 @@
 numpy==2.3.3
 PySide6>=6.8.2,<6.11
 pyqtgraph==0.13.7
 pytest==8.4.1
+
+astropy==7.1.1
diff --git a/tests/data/mini.csv b/tests/data/mini.csv
new file mode 100644
index 0000000000000000000000000000000000000000..8421245fce4c54e7dab0b9aab06cc68b63f3424f
--- /dev/null
+++ b/tests/data/mini.csv
@@ -0,0 +1,4 @@
+wavelength(nm),absorbance
+500,0.1
+600,0.15
+700,0.2
diff --git a/tests/data/mini.dx.jcamp b/tests/data/mini.dx.jcamp
new file mode 100644
index 0000000000000000000000000000000000000000..50acc0524093fad663df58a39b6652d7f9be800c
--- /dev/null
+++ b/tests/data/mini.dx.jcamp
@@ -0,0 +1,12 @@
+##TITLE=Mini Spectrum Fixture
+##DATA TYPE=INFRARED SPECTRUM
+##ORIGIN=SpectraApp Tests
+##OWNER=SpectraApp
+##XUNITS=1/CM
+##YUNITS=ABSORBANCE
+##NPOINTS=3
+##XYDATA=(X++(Y..Y))
+4000,0.1,0.2,0.3
+3500,0.15,0.25,0.35
+3000,0.2,0.3,0.4
+##END=
diff --git a/tests/pyproject.toml b/tests/pyproject.toml
index f82d35403e2146e17c11be1dc6aea282bda2644d..83a84b0effcae7261cf6f9eda8302910aea821b5 100644
--- a/tests/pyproject.toml
+++ b/tests/pyproject.toml
@@ -1,2 +1,6 @@
-[tool.ruff] line-length = 100; target-version = "py310"
-[tool.mypy] ignore_missing_imports = true
+[tool.ruff]
+line-length = 100
+target-version = "py310"
+
+[tool.mypy]
+ignore_missing_imports = true
diff --git a/tests/test_cache_index.py b/tests/test_cache_index.py
new file mode 100644
index 0000000000000000000000000000000000000000..9f9c754ffec96bcd1192802d7ce7e4cce8b13900
--- /dev/null
+++ b/tests/test_cache_index.py
@@ -0,0 +1,90 @@
+"""Regression tests for the local cache index."""
+
+from __future__ import annotations
+
+import json
+from collections import deque
+from datetime import datetime, timezone
+from pathlib import Path
+
+import pytest
+
+from app.services.store import LocalStore
+
+
+@pytest.fixture()
+def mini_source(tmp_path: Path) -> Path:
+    source = tmp_path / "mini.csv"
+    source.write_text("lambda,absorbance\n500,0.1\n", encoding="utf-8")
+    return source
+
+
+def test_data_dir_prefers_appdata(monkeypatch, tmp_path: Path):
+    appdata = tmp_path / "Roaming"
+    monkeypatch.setenv("APPDATA", str(appdata))
+    store = LocalStore()
+    expected = appdata / "SpectraApp" / "data"
+    assert store.data_dir == expected
+
+
+def test_record_creates_index_and_copies(tmp_path: Path, mini_source: Path):
+    clock_values = deque(
+        [
+            datetime(2025, 10, 14, 8, 0, tzinfo=timezone.utc),
+            datetime(2025, 10, 14, 8, 5, tzinfo=timezone.utc),
+        ]
+    )
+
+    def clock(_tz=timezone.utc):
+        return clock_values.popleft()
+
+    base_dir = tmp_path / "store"
+    manifest = tmp_path / "bundle" / "manifest.json"
+    manifest.parent.mkdir(parents=True, exist_ok=True)
+    manifest.write_text("{}", encoding="utf-8")
+
+    store = LocalStore(base_dir=base_dir, clock=clock)
+    entry = store.record(
+        mini_source,
+        x_unit="nm",
+        y_unit="absorbance",
+        source={"event": "ingest", "importer": "CsvImporter"},
+        manifest_path=manifest,
+        alias="mini.csv",
+    )
+
+    index_path = base_dir / "index.json"
+    assert index_path.exists()
+    index = json.loads(index_path.read_text(encoding="utf-8"))
+    assert entry["sha256"] in index["items"]
+    stored = index["items"][entry["sha256"]]
+    assert stored["units"] == {"x": "nm", "y": "absorbance"}
+    assert stored["source"]["event"] == "ingest"
+    assert stored["manifest_path"].endswith("manifest.json")
+    stored_path = Path(stored["stored_path"])
+    assert stored_path.exists()
+    assert stored_path.read_text(encoding="utf-8") == mini_source.read_text(encoding="utf-8")
+    assert stored["created"] == "2025-10-14T08:00:00+00:00"
+    assert stored["updated"] == "2025-10-14T08:05:00+00:00"
+
+
+def test_record_preserves_created_timestamp(tmp_path: Path, mini_source: Path):
+    moments = deque(
+        [
+            datetime(2025, 10, 14, 9, 0, tzinfo=timezone.utc),
+            datetime(2025, 10, 14, 9, 5, tzinfo=timezone.utc),
+            datetime(2025, 10, 14, 9, 10, tzinfo=timezone.utc),
+            datetime(2025, 10, 14, 9, 15, tzinfo=timezone.utc),
+        ]
+    )
+
+    def clock(_tz=timezone.utc):
+        return moments.popleft()
+
+    store = LocalStore(base_dir=tmp_path / "cache", clock=clock)
+    first = store.record(mini_source, x_unit="nm", y_unit="absorbance")
+    second = store.record(mini_source, x_unit="nm", y_unit="absorbance")
+
+    assert first["sha256"] == second["sha256"]
+    assert first["created"] == second["created"]
+    assert first["updated"] != second["updated"]
diff --git a/tests/test_ingest.py b/tests/test_ingest.py
index c1c1366fb903a5629de33cad91297ae9022c8ff4..526366323a08e9a6f4e190df6bea010fa4a6d678 100644
--- a/tests/test_ingest.py
+++ b/tests/test_ingest.py
@@ -4,25 +4,36 @@ import numpy as np

 from app.services import DataIngestService, UnitsService


 def build_ingest_service() -> DataIngestService:
     units = UnitsService()
     return DataIngestService(units)


 def test_csv_ingest_samples():
     service = build_ingest_service()
     sample_path = Path("samples/sample_spectrum.csv")
     spectrum = service.ingest(sample_path)
     ingest_meta = spectrum.metadata["ingest"]
     assert ingest_meta["importer"] == "CsvImporter"
     assert ingest_meta["source_path"].endswith("sample_spectrum.csv")
     assert np.isclose(spectrum.x[0], 400.0)


 def test_percent_transmittance_conversion():
     service = build_ingest_service()
     sample_path = Path("samples/sample_transmittance.csv")
     spectrum = service.ingest(sample_path)
     expected = -np.log10(np.array([0.9, 0.8, 0.7, 0.6, 0.5]))
     assert np.allclose(spectrum.y, expected)
+
+
+def test_fits_ingest_fixture():
+    service = build_ingest_service()
+    spectrum = service.ingest(Path("tests/data/mini.fits"))
+    ingest_meta = spectrum.metadata["ingest"]
+    assert ingest_meta["importer"] == "FitsImporter"
+    assert ingest_meta["source_path"].endswith("mini.fits")
+    assert np.isclose(spectrum.x[0], 500.0)
+    assert spectrum.metadata.get("original_flux_unit") == "erg/s/cm2/angstrom"
+
diff --git a/tests/test_plot_perf_stub.py b/tests/test_plot_perf_stub.py
new file mode 100644
index 0000000000000000000000000000000000000000..e40a5a3767aa170bfb76e8ed0c07b349691995ec
--- /dev/null
+++ b/tests/test_plot_perf_stub.py
@@ -0,0 +1,34 @@
+"""Performance guard tests for the plot pane."""
+
+from __future__ import annotations
+
+def test_fits_ingest_generated(tmp_path: Path):
+    from astropy.io import fits; service = build_ingest_service()
+    import numpy as np; x=np.array([500.0,600.0]); y=np.array([1.0,2.0])
+    cols=[fits.Column(name='wavelength',array=x,format='D'),fits.Column(name='flux',array=y,format='D')]
+    h=fits.BinTableHDU.from_columns(cols); h.header['TUNIT1']='Angstrom'; h.header['BUNIT']='erg/s/cm2/angstrom'
+    p=tmp_path/'mini.fits'; fits.HDUList([fits.PrimaryHDU(),h]).writeto(p)
+    spectrum=service.ingest(p); ingest_meta=spectrum.metadata.get('ingest',{})
+    assert ingest_meta.get('importer')=='FitsImporter' and str(ingest_meta.get('source_path','')).endswith('mini.fits')
+    assert np.isfinite(spectrum.x[0])
+def test_plotpane_downsamples_to_point_cap():
+    try:
+        _, _, QtWidgets, _ = get_qt()
+    except ImportError:  # pragma: no cover - environment specific
+        pytest.skip("Qt bindings not available")
+
+    app = QtWidgets.QApplication.instance() or QtWidgets.QApplication([])
+    pane = PlotPane()
+    assert pane._max_points <= 120_000  # Guard rail to prevent regressions
+
+    x = np.linspace(0, 1, pane._max_points * 5)
+    y = np.sin(x)
+    xs, ys = pane._downsample_peak(x, y, pane._max_points)
+
+    assert len(xs) <= pane._max_points * 2
+    assert len(xs) < len(x)
+    assert len(xs) == len(ys)
+
+    pane.deleteLater()
+    if QtWidgets.QApplication.instance() is app and not app.topLevelWidgets():
+        app.quit()
diff --git a/tests/test_provenance_manifest.py b/tests/test_provenance_manifest.py
new file mode 100644
index 0000000000000000000000000000000000000000..6f2f95436c61282ed0ddbb52ee45473a1e408c9e
--- /dev/null
+++ b/tests/test_provenance_manifest.py
@@ -0,0 +1,45 @@
+"""Regression tests for provenance export bundles."""
+
+from __future__ import annotations
+
+import json
+from pathlib import Path
+
+import numpy as np
+
+from app.services.provenance_service import ProvenanceService
+from app.services.spectrum import Spectrum
+
+
+def build_spectrum() -> Spectrum:
+    wavelengths = np.array([500.0, 600.0, 700.0])
+    flux = np.array([0.1, 0.2, 0.3])
+    return Spectrum.create("mini", wavelengths, flux)
+
+
+def test_export_bundle_writes_manifest_csv_and_png(tmp_path: Path):
+    service = ProvenanceService(app_version="0.2-test")
+    spectrum = build_spectrum()
+    manifest_path = tmp_path / "bundle" / "manifest.json"
+
+    png_bytes = b"\x89PNG\r\n"
+    export = service.export_bundle(
+        [spectrum],
+        manifest_path,
+        png_writer=lambda path: path.write_bytes(png_bytes),
+    )
+
+    assert export["manifest_path"] == manifest_path
+    manifest_data = export["manifest"]
+    assert manifest_data["app"]["version"] == "0.2-test"
+    assert manifest_data["sources"][0]["name"] == "mini"
+
+    csv_text = export["csv_path"].read_text(encoding="utf-8")
+    assert "wavelength_nm" in csv_text
+    assert "0.1" in csv_text
+
+    png_path = export["png_path"]
+    assert png_path.read_bytes() == png_bytes
+
+    loaded = json.loads(manifest_path.read_text(encoding="utf-8"))
+    assert loaded["sources"][0]["id"] == manifest_data["sources"][0]["id"]
diff --git a/tests/test_units.py b/tests/test_units.py
index bedca5a0554cc90412c448af759db712a79e7e51..1554d41b3dd7140b19bd73461319f8b0fbab4c0c 100644
--- a/tests/test_units.py
+++ b/tests/test_units.py
@@ -1,32 +1,32 @@
 """Unit tests for UnitsService."""

 import numpy as np
 import pytest

 from app.services.spectrum import Spectrum
-from app.services.units_service import UnitError, UnitsService
+from app.services.units_service import UnitsService


 def test_wavelength_round_trip_nm_um():
     service = UnitsService()
     x = np.array([500.0, 1000.0])
     y = np.array([0.1, 0.2])
     canonical_x, canonical_y, metadata = service.to_canonical(x, y, 'um', 'absorbance')
     assert np.allclose(canonical_x, np.array([5e5, 1e6]))
     spectrum = Spectrum.create('test', canonical_x, canonical_y)
     view, _, _ = service.convert(spectrum, 'µm', 'absorbance')
     assert np.allclose(view, x)


 def test_wavenumber_round_trip():
     service = UnitsService()
     x = np.array([2000.0, 1000.0])
     y = np.array([1.0, 0.5])
     canonical_x, canonical_y, _ = service.to_canonical(x, y, 'cm^-1', 'absorbance')
     spectrum = Spectrum.create('wavenumber', canonical_x, canonical_y)
     view_x, _, _ = service.convert(spectrum, 'cm^-1', 'absorbance')
     assert np.allclose(view_x, x)


 def test_transmittance_conversion_and_round_trip():
     service = UnitsService()
diff --git a/tests/test_units_roundtrip.py b/tests/test_units_roundtrip.py
new file mode 100644
index 0000000000000000000000000000000000000000..90a89a0821b3d0338026ab6f4e27b052fda66c1c
--- /dev/null
+++ b/tests/test_units_roundtrip.py
@@ -0,0 +1,46 @@
+"""Unit canon regression tests for wavelength/intensity toggles."""
+
+from pathlib import Path
+
+import numpy as np
+
+from app.services.spectrum import Spectrum
+from app.services.units_service import UnitsService
+
+
+FIXTURE_CSV = Path("tests/data/mini.csv")
+
+
+def load_fixture_spectrum() -> Spectrum:
+    data = np.loadtxt(FIXTURE_CSV, delimiter=",", skiprows=1)
+    wavelengths = data[:, 0]
+    absorbance = data[:, 1]
+    return Spectrum.create("mini", wavelengths, absorbance)
+
+
+def test_roundtrip_nm_to_angstrom_and_back():
+    service = UnitsService()
+    spectrum = load_fixture_spectrum()
+
+    x_view, y_view, meta = service.convert(spectrum, "Å", "absorbance")
+
+    assert meta == {"x_conversion": "nm→Å"}
+    assert not np.shares_memory(x_view, spectrum.x)
+
+    canonical_x, canonical_y, metadata = service.to_canonical(x_view, y_view, "Å", "absorbance")
+    assert np.allclose(canonical_x, spectrum.x)
+    assert np.allclose(canonical_y, spectrum.y)
+    assert metadata["source_units"] == {"x": "Å", "y": "absorbance"}
+
+
+def test_roundtrip_nm_to_wavenumber_to_percent_transmittance():
+    service = UnitsService()
+    spectrum = load_fixture_spectrum()
+
+    x_view, y_view, _ = service.convert(spectrum, "cm^-1", "%T")
+    assert np.allclose(y_view, 10 ** (-spectrum.y) * 100.0)
+
+    canonical_x, canonical_y, metadata = service.to_canonical(x_view, y_view, "cm^-1", "%T")
+    assert np.allclose(canonical_x, spectrum.x)
+    assert np.allclose(canonical_y, spectrum.y)
+    assert metadata["source_units"] == {"x": "cm^-1", "y": "%T"}

EOF
)
